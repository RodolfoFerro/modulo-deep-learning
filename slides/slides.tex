\documentclass[10pt,border=3pt,tikz]{beamer}

\usepackage{pgfpages}
\usepackage[T1]{fontenc}

\usepackage{pdfpages}

\usepackage{tikz}
\usetikzlibrary{matrix, positioning}
\usetikzlibrary{decorations.pathreplacing}
\usepackage{etoolbox}
\usepackage{listofitems} % for \readlist to create arrays
\tikzstyle{mynode}=[thick,draw=blue,fill=blue!20,circle,minimum size=15]
%\setbeameroption{show notes on second screen }
\usetheme[
% nojauge,
% nomail,
% rule,
delaunay,
amurmapleblack
]{Amurmaple}

\usepackage{amsmath}
\usepackage{lipsum}
\usepackage{emoji}
\graphicspath{ {./images/} }

\usepackage{xcolor}
\colorlet{myred}{red!80!black}
\colorlet{myblue}{blue!80!black}
\colorlet{mygreen}{green!60!black}
\colorlet{myorange}{orange!70!red!60!black}
\colorlet{mydarkred}{red!30!black}
\colorlet{mydarkblue}{blue!40!black}
\colorlet{mydarkgreen}{green!30!black}
\tikzset{
    >=latex, % for default LaTeX arrow head
    node/.style={thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6},
    node in/.style={node,green!20!black,draw=mygreen!30!black,fill=mygreen!25},
    node hidden/.style={node,blue!20!black,draw=myblue!30!black,fill=myblue!20},
    node convol/.style={node,orange!20!black,draw=myorange!30!black,fill=myorange!20},
    node out/.style={node,red!20!black,draw=myred!30!black,fill=myred!20},
    connect/.style={thick,mydarkblue}, %,line cap=round
    connect arrow/.style={-{Latex[length=4,width=3.5]},thick,mydarkblue,shorten <=0.5,shorten >=1},
    node 1/.style={node in}, % node styles, numbered for easy mapping with \nstyle
    node 2/.style={node hidden},
    node 3/.style={node out}
}
\def\nstyle{int(\lay<\Nnodlen?min(2,\lay):3)} % map layer number onto 1, 2, or 3

\definecolor{newremark}{rgb}{0.7,0.2,0.2}
\colorlet{AmurmapleRemarkColor}{newremark}

\title[Deep Learning]{Aprendizaje profundo}
\author[R.~Ferro (@rodo\_ferro)]{Rodolfo Ferro}
\subtitle{Módulo 5}
\institute[ENES Unidad León]{Diplomado en Ciencia de Datos\\
	Escuela Nacional de Estudios Superiores, Unidad León}
\date{Agosto, 2024}
\titlegraphic{\includegraphics[width=3cm]{logo.png}}
\mail{ferro@cimat.mx}
\webpage{https://rodolfoferro.xyz}
% \collaboration{in collaboration with \LaTeX{}}
\logo{\includegraphics[width=1.6cm]{logo.png}}

\begin{document}
    
	\maketitle
    
        
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    
    % ----------- Presentación ------------------
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{frame}{Tutor del módulo}{Aprendizaje profundo}
        \begin{columns}
            % Columna izquierda
            \begin{column}{0.7\textwidth}
                \textbf{Rodolfo Ferro} (\href{mailto:ferro@cimat.mx}{ferro@cimat.mx})
                {\scriptsize \begin{itemize}
                    \item Sr. SWE (Data Engineer) @ Bisonic México
                    \item Miembro del Consejo Consultivo para el Desarrollo Económico, Creatividad e Innovación de León
                    \item \textbf{Formación:} BMath, CSysEng, StatMethodsSpc (\textit{ongoing})
                    \item \textbf{Experiencia:} ML Engineer @ Vindoo.ai (España), Sherpa Digital en IA @ Microsoft México, AI Research Assistant @ CIMAT \& AI Research Intern @ Harvard.
                \end{itemize}}
            \end{column}
            % Columna derecha
            \begin{column}{0.25\textwidth}
                \begin{figure}
                    \centering
                    \includegraphics[width=1\textwidth]{rodo.png}
                \end{figure}
            \end{column}
        \end{columns}
    \end{frame}
	
	\sepframe[title={Tabla de contenidos}]
	
    \frame{\tableofcontents}

	
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    
    % ----------- Intro al DL --------------------
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Intro al aprendizaje profundo}
    
    % ----------- Motivación 01 ------------------
    \subsection{Motivación}
    
    \begin{frame}{Motivación}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{motivation-01}
        \end{figure}
    \end{frame}
    
    % ----------- Motivación 02 ------------------
    \begin{frame}{Motivación}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{motivation-02}
        \end{figure}
    \end{frame}
    
    % ----------- Motivación 03 ------------------
    \begin{frame}{Motivación}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{motivation-03}
        \end{figure}
    \end{frame}

    % ----------- Motivación 04 ------------------
    \begin{frame}{Motivación}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{motivation-04}
        \end{figure}
    \end{frame}
    
    % ----------- ¿Qué es el DL? 01 --------------
    \subsection{Introducción}
    
    \begin{frame}{¿Qué es el \textsl{Deep Learning}?}{Intro al aprendizaje profundo}
        \begin{quotation}[David Foster (Generative Deep Learning)]
            El aprendizaje profundo (Deep Learning) comprende algoritmos de Machine Learning que (particularmente) utilizan múltiples capas apiladas de unidades de procesamiento para aprender representaciones en un alto nivel sobre datos no estructurados.
        \end{quotation}
    \end{frame}
    
    % ----------- ¿Qué es el DL? 02 --------------
    \begin{frame}{¿Qué es el \textsl{Deep Learning}?}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{ai-ml-dl}
        \end{figure}
    \end{frame}
    
    % ----------- ¿Qué es el DL? 03 --------------
    \begin{frame}{¿Qué es el \textsl{Deep Learning}?}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{itemize}
                \item \textbf{Inteligencia artificial:} Cualquier técnica que permita
                a las computadoras emular o imitar el comportamiento humano.
                \item \textbf{Aprendizaje de máquina:} Capacidad de aprender sin ser programado explícitamente, enfoque en los algoritmos y la matemtica.
                \item \textbf{Aprendizaje profundo:} Extrae patrones de datos utilizando redes neuronales.
            \end{itemize}
        \end{center}
    \end{frame}
    
    % ----------- ¿Por qué el DL? 01 ------------
    \begin{frame}{¿Por qué el \textsl{Deep Learning}?}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{ml-01}
        \end{figure}
    \end{frame}

    % ----------- ¿Por qué el DL? 02 ------------
    \begin{frame}{¿Por qué el \textsl{Deep Learning}?}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{ml-02}
        \end{figure}
    \end{frame}
    
    % ----------- ¿Por qué el DL? 02 ------------
    \begin{frame}{¿Por qué el \textsl{Deep Learning}?}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{itemize}
                \item La ingeniería de características requiere mucho tiempo, es suceptible a errores y no es escalable consistentemente con datos complejos. Mejor busquemos aprender las características subyacentes directamente de los datos.
                \item Las redes neuronales artificales existen desde hace décadas, pero su predominio actual reside principalmente en los siguientes tres aspectos:
                \begin{enumerate}
                    \item Hardware (GPUs, etc. + Paralelización)
                    \item Software (Frameworks para trabajar con NNs)
                    \item Grandes cantidades de datos
                \end{enumerate}
                \item El aprendizaje profundo está revolucionando muchos campos.
            \end{itemize}
        \end{center}
    \end{frame}
    
    % ----------- Contexto histórico ------------
    \subsection{Contexto histórico}
    
    \begin{frame}{Contexto histórico}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{santiago}
            \caption{Santiago Ramón y Cajal}
        \end{figure}
    \end{frame}
    
    % ----------- Santiago Ramón y Cajal --------
    \begin{frame}{Contexto histórico}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.3\textwidth]{santiago-neuron} $\longrightarrow$
            \includegraphics[width=0.5\textwidth]{neuron}
            
            \let\thefootnote\relax\footnote{{\tiny “Santiago Ramón y Cajal Drawings.” Janelia Research Campus. Accessed July 5, 2024. \href{https://www.janelia.org/archive/santiago-ramón-y-cajal-drawings}{https://www.janelia.org}}}
            
            \let\thefootnote\relax\footnote{{\tiny “Overview of Neuron Structure and Function (Article).” Khan Academy. Accessed July 5, 2024. \href{https://www.khanacademy.org/science/biology/human-biology/neuron-nervous-system/a/overview-of-neuron-structure-and-function}{https://www.khanacademy.org}}}
        \end{figure}
    \end{frame}
    
    % ----------- McCulloch & Pitts -------------
    \begin{frame}{TLU}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{mcculloch-pitts}
            \caption{Warren McCulloch \& Walter Pitts}
        \end{figure}
    \end{frame}
    
    % ----------- TLU ---------------------------
    \begin{frame}{TLU}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{weight}=[draw,shape=rectangle,minimum size=0.5cm,fill=gray!20]
                \tikzstyle{sum}=[draw,shape=circle,minimum size=1cm,fill=yellow!20]
                \tikzstyle{activation}=[draw,shape=rectangle,minimum size=0.5cm,fill=blue!20]
                \tikzstyle{output}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]
                
                
                \node[unit](x1) at (-1.5,2.5){$x_1$};
                \node[unit](x2) at (-1.5,1.5){$x_2$};
                \node(dots) at (-1.5,0.75){\vdots};
                \node[unit](xn) at (-1.5,-0.25){$x_n$};
                
                
                \node[weight](w1) at (0.25,2.5){$w_1$};
                \node[weight](w2) at (0.25,1.5){$w_2$};
                \node[weight](wn) at (0.25,-0.25){$w_n$};
                
                \node[sum](p) at (2,1){$\Sigma$};
                \node[activation](a) at (3.5,1){$H$};
                \node[output](o) at (5,1){$y$};
                
                \draw (x1) -- (w1);
                \draw (x2) -- (w2);
                \draw (xn) -- (wn);
                \draw[->] (w1) -- (p);
                \draw[->] (w2) -- (p);
                \draw[->] (wn) -- (p);
                \draw[->] (p) -- (a);
                \draw[->] (a) -- (o);
                
                \draw [decorate,decoration={brace,amplitude=10pt},xshift=-4pt,yshift=0pt] (-2,3) -- (-0.75,3) node [black,midway,yshift=+0.6cm]{entrada};
                \draw [decorate,decoration={brace,amplitude=10pt},xshift=-4pt,yshift=0pt] (-0.25,3) -- (1,3) node [black,midway,yshift=+0.6cm]{pesos};
                \draw [decorate,decoration={brace,amplitude=10pt},xshift=-4pt,yshift=0pt] (4.5,1.5) -- (5.75,1.5) node [black,midway,yshift=+0.6cm]{salida};
                
                \draw[->] (1,-1.75)node[sum]{$\Sigma$} -- (3,-1.75)[xshift=30]node{$\displaystyle\sum_{i=1}^{n}w_ix_i$};
            \end{tikzpicture}
        \end{center}
    \end{frame}
    
    % -------- Bias y función de activación 01 --
    \begin{frame}{Bias y función de activación}{Intro al aprendizaje profundo}
        La operación matemática que realiza la neurona para la decisión de umbralización se puede escribir como:
        
        $$ f(\textbf{x}) =
        \begin{cases}
            0 & \text{si $\displaystyle\sum_{i}w_ix_i <$ umbral o threshold} \\
            1 & \text{si $\displaystyle\sum_{i}w_ix_i \geq$ umbral o threshold} \\
        \end{cases}$$
        
        donde $i \in \{1, 2, ..., n\}$, y así, $\textbf{x} = (x_1, x_2, ..., x_n)$.
    \end{frame}
    
    % -------- Bias y función de activación 01 --
    \begin{frame}{Bias y función de activación}{Intro al aprendizaje profundo}
        De lo anterior, podemos despejar el umbral y escribirlo como $b$, obteniendo:
        
        $$ f(\textbf{x}) =
        \begin{cases}
            0 & \text{si $\displaystyle\sum_{i}w_ix_i + b < 0$} \\
            1 & \text{si $\displaystyle\sum_{i}w_ix_i + b > 0$} \\
        \end{cases}$$
        
        donde $\textbf{x} = (x_1, x_2, ..., x_n)$ y $i \in \{1, 2, ..., n\}$.

        A esto que escribimos como $b$, también se le conoce como \textbf{bias}, y una interpretación es describir \textit{qué tan susceptible es la neurona a \textbf{dispararse}} (como se exploró en el ejemplo práctico de la identificación de la actividad de Julieta).
    \end{frame}
    
    % -------- Bias y función de activación 03 --
    \begin{frame}{Bias y función de activación}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.425\textwidth]{heavyside} $\longrightarrow$
            \includegraphics[width=0.45\textwidth]{sigmoid-plot}
        \end{figure}
    \end{frame}
    
    % ----------- El Perceptrón 01 --------------
    \subsection{Perceptrón}
    
    \begin{frame}{El Perceptrón}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{rosenblatt}
            \caption{Frank Rosenblatt}
        \end{figure}
    \end{frame}
    
    
    % ----------- El Perceptrón 02 --------------
    \begin{frame}{El Perceptrón}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{bias}=[draw,shape=circle,minimum size=0.8cm,fill=green!10]
                \tikzstyle{weight}=[draw,shape=rectangle,minimum size=0.5cm,fill=gray!20]
                \tikzstyle{sum}=[draw,shape=circle,minimum size=1cm,fill=yellow!20]
                \tikzstyle{activation}=[draw,shape=rectangle,minimum size=0.5cm,fill=blue!20]
                \tikzstyle{output}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]
                
                
                \node[unit](x1) at (-1.5,2.5){$x_1$};
                \node[unit](x2) at (-1.5,1.5){$x_2$};
                \node(dots) at (-1.5,0.75){\vdots};
                \node[unit](xn) at (-1.5,-0.25){$x_n$};
                \node[bias](b) at (-1.5,-1.25){$b$};
                
                
                \node[weight](w1) at (0.25,2.5){$w_1$};
                \node[weight](w2) at (0.25,1.5){$w_2$};
                \node[weight](wn) at (0.25,-0.25){$w_n$};
                \node[weight](wb) at (0.25,-1.25){$1$};
                
                \node[sum](p) at (2,1){$\Sigma$};
                \node[activation](a) at (3.5,1){$\sigma$};
                \node[output](o) at (5,1){$y$};
                
                \draw (x1) -- (w1);
                \draw (x2) -- (w2);
                \draw (xn) -- (wn);
                \draw (b) -- (wb);
                \draw[->] (w1) -- (p);
                \draw[->] (w2) -- (p);
                \draw[->] (wn) -- (p);
                \draw[->] (wb) -- (p);
                \draw[->] (p) -- (a);
                \draw[->] (a) -- (o);
            \end{tikzpicture}
            
            \vspace{20pt}
            ¡Y se agrega un algoritmo formal de entrenamiento!\\(\textit{Backpropagation})
        \end{center}
    \end{frame}
    
    % ----------- Idea de entrenamiento 01 ------
    \begin{frame}{Idea intuitiva de entrenamiento}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{training-idea-01}
        \end{figure}
    \end{frame}
    
    % ----------- Idea de entrenamiento 02 ------
    \begin{frame}{Idea intuitiva de entrenamiento}{Intro al aprendizaje profundo}
    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{training-idea-02}
    \end{figure}
    \end{frame}
    
    % ----------- Idea de entrenamiento 03 ------
    \begin{frame}{Idea intuitiva de entrenamiento}{Intro al aprendizaje profundo}
    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{training-idea-03}
    \end{figure}
    \end{frame}
    
    % ----------- Idea de entrenamiento 04 ------
    \begin{frame}{Idea intuitiva de entrenamiento}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{training-idea-04}
        \end{figure}
    \end{frame}
    
    % ----------- Idea de entrenamiento 05 ------
    \begin{frame}{Medición del error}{Intro al aprendizaje profundo}
        Dado el vector $X$, \textbf{¿qué vector ($A, B, C$) se le \textit{parece} más?}
        
        \begin{align*}
            X &= \begin{bmatrix}
                0.5 \\
                0.3 \\
                0.7
            \end{bmatrix}
        \end{align*}
        
        \begin{align*}
            A = \begin{bmatrix}
                0.3 \\
                0.3 \\
                0.3
            \end{bmatrix},
            B = \begin{bmatrix}
                0.6 \\
                0.2 \\
                0.6
            \end{bmatrix},
            C = \begin{bmatrix}
                -0.5 \\
                -0.3 \\
                -0.7
            \end{bmatrix}
        \end{align*}
    \end{frame}
    
    % ----------- Idea de entrenamiento 05 ------
    \begin{frame}{Medición del error}{Intro al aprendizaje profundo}
        Dado el vector $X$, \textbf{¿qué vector ($A, B, C$) se le \textit{parece} más?}
        
        \begin{align*}
            X &= \begin{bmatrix}
                0.5 \\
                0.3 \\
                0.7
            \end{bmatrix}
        \end{align*}
        
        \begin{align*}
            A = \begin{bmatrix}
                0.3 \\
                0.3 \\
                0.3
            \end{bmatrix},
            \colorbox{green!20}{$B = \begin{bmatrix}
                0.6 \\
                0.2 \\
                0.6
            \end{bmatrix}$},
            C = \begin{bmatrix}
                -0.5 \\
                -0.3 \\
                -0.7
            \end{bmatrix}
        \end{align*}
    \end{frame}
    
    % ----------- Idea de entrenamiento 06 ------
    \begin{frame}{Optimización del error}{Intro al aprendizaje profundo}
        \begin{columns}
            % Columna izquierda
            \begin{column}{0.6\textwidth}
                \begin{itemize}
                    \item \textbf{Error:} Es una función.
                    \item \textbf{Optimizar:} Maximizar o minimizar.
                    \item \textbf{Gradiente:} Derivada de una función vectorial, proporciona información sobre máximos o mínimos.
                    \item \textbf{Descenso de gradiente:} Algoritmo para, iterativamente, buscar optimizar una función.
                    \item \textbf{Limitantes:} 
                        \begin{itemize}
                            \item Max's/min's locales.
                            \item Tamaño de salto en gradiente
                        \end{itemize}
                \end{itemize}
            \end{column}
            % Columna derecha
            \begin{column}{0.35\textwidth}
                \begin{figure}
                    \centering
                    \includegraphics[width=1\textwidth]{gd}
                \end{figure}
            \end{column}
        \end{columns}
    \end{frame}
    
    % ----------- Observaciones 01 ----------------
    \begin{frame}{Observaciones}{Intro al aprendizaje profundo}
        Hasta este punto, debemos notar que hay algunas observaciones importantes:
        \begin{itemize}
            \item \textbf{TLUs:} 
            \begin{itemize}
                \item No existe un algoritmo de aprendizaje formal → Búsqueda de pesos.
                \item Se limita a propagación hacia adelante (\textit{forward pass/forward propagation})
            \end{itemize}
            \item \textbf{Perceptrón:} Puede utilizar retropropagación, introducido en 1958.
            \item \textbf{Retropropagación:} Algoritmo para realizar ajustes en los valores de los pesos.
            \item \textbf{Limitantes:} Separabilidad lineal.
            \item \textbf{¿Alguna otra observación?}
        \end{itemize}
    \end{frame}
    
    % ----------- Ejercicio 01 ------------------
    \begin{frame}{Ejercicio}{Intro al aprendizaje profundo}
        \begin{center}
            {\Large \textbf{Ejercicio: Manzanas vs. Naranjas}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.4\textwidth]{apple-orange}
        \end{figure}
    \end{frame}
    
    % ----------- Lecturas recomendadas 01 ------
    \begin{frame}{Lecturas recomendadas}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item Breve historia sobre \colorbox{blue!10}{\href{https://telefonicatech.com/blog/historia-de-la-ia-frank-rosenblatt-y-e}{el perceptrón}}
            \item Post sobre \colorbox{blue!10}{\href{https://lamaquinaoraculo.com/deep-learning/el-perceptron-de-rosenblatt/}{el perceptrón de Rosenblatt}}
            \item Post sobre la \colorbox{blue!10}{\href{https://lamaquinaoraculo.com/deep-learning/la-funcion-de-activacion/}{función de activación}}
            \item \colorbox{blue!10}{\href{https://ploomber.io/blog/threshold/}{Selección de threshold}} para clasificadores binarios
            \item Post sobre \colorbox{blue!10}{\href{https://www.ibm.com/mx-es/topics/neural-networks}{redes neuronales}} por IBM
        \end{itemize}
    \end{frame}
    
    % ----------- Producto matricial 01 ---------
    \subsection{Perceptrón multicapa}
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        Recordemos cómo opera el producto matricial:
        
        $$\begin{bmatrix}
            2 & 5 & 2\\
            1 & 0 & -2\\
            3 & 1 & 1
        \end{bmatrix}
        \begin{bmatrix}
        -2 & 1 & 0\\
        -2 & 2 & 1\\
        0 & 0 & 3
        \end{bmatrix} = 
        \begin{bmatrix}
         &  & \\
         &  & \\
         &  & 
        \end{bmatrix}$$
    \end{frame}
    
    % ----------- Producto matricial 02 ---------
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        Recordemos cómo opera el producto matricial:
        
        $$\begin{bmatrix}
            \colorbox{blue!10}{2} & \colorbox{blue!10}{5} & \colorbox{blue!10}{2}\\
            1 & 0 & -2\\
            3 & 1 & 1
        \end{bmatrix}
        \begin{bmatrix}
            \colorbox{blue!10}{-2} & 1 & 0\\
            \colorbox{blue!10}{-2} & 2 & 1\\
            \colorbox{blue!10}{0} & 0 & 3
        \end{bmatrix} = 
        \begin{bmatrix}
           \colorbox{blue!10}{14} &  & \\
            &  & \\
            &  & 
        \end{bmatrix}$$
        
        $$(2 \cdot -2) + (5 \cdot -2) + (2 \cdot 0) = -14$$
    \end{frame}
    
    % ----------- Producto matricial 03 ---------
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        Recordemos cómo opera el producto matricial:
        
        $$\begin{bmatrix}
            \colorbox{blue!10}{2} & \colorbox{blue!10}{5} & \colorbox{blue!10}{2}\\
            1 & 0 & -2\\
            3 & 1 & 1
        \end{bmatrix}
        \begin{bmatrix}
            -2 & \colorbox{blue!10}{1} & 0\\
            -2 & \colorbox{blue!10}{2} & 1\\
            0 & \colorbox{blue!10}{0} & 3
        \end{bmatrix} = 
        \begin{bmatrix}
            14 & \colorbox{blue!10}{12} & \\
            &  & \\
            &  & 
        \end{bmatrix}$$
        
        $$(2 \cdot 1) + (5 \cdot 2) + (2 \cdot 0) = 12$$
    \end{frame}
    
    % ----------- Producto matricial 04 ---------
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        Recordemos cómo opera el producto matricial:
        
        $$\begin{bmatrix}
            \colorbox{blue!10}{2} & \colorbox{blue!10}{5} & \colorbox{blue!10}{2}\\
            1 & 0 & -2\\
            3 & 1 & 1
        \end{bmatrix}
        \begin{bmatrix}
        -2 & 1 & \colorbox{blue!10}{0}\\
        -2 & 2 & \colorbox{blue!10}{1}\\
        0 & 0 & \colorbox{blue!10}{3}
        \end{bmatrix} = 
        \begin{bmatrix}
            14 & 12 & \colorbox{blue!10}{11}\\
            &  & \\
            &  & 
        \end{bmatrix}$$
        
        $$(2 \cdot 0) + (5 \cdot 1) + (2 \cdot 3) = 11$$
    \end{frame}
    
    % ----------- Producto matricial 05 ---------
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        Recordemos cómo opera el producto matricial:
        
        $$\begin{bmatrix}
            2 & 5 & 2\\
            \colorbox{blue!10}{1} & \colorbox{blue!10}{0} & \colorbox{blue!10}{-2}\\
            3 & 1 & 1
        \end{bmatrix}
        \begin{bmatrix}
            \colorbox{blue!10}{-2} & 1 & 0\\
            \colorbox{blue!10}{-2} & 2 & 1\\
            \colorbox{blue!10}{0} & 0 & 3
        \end{bmatrix} = 
        \begin{bmatrix}
            14 & 12 & 11\\
            \colorbox{blue!10}{-2} &  & \\
            &  & 
        \end{bmatrix}$$
        
        $$(1 \cdot -2) + (0 \cdot -2) + (-2 \cdot 0) = -2$$
    \end{frame}
    
    % ----------- Producto matricial 06 ---------
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        Recordemos cómo opera el producto matricial:
        
        $$\begin{bmatrix}
            2 & 5 & 2\\
            \colorbox{blue!10}{1} & \colorbox{blue!10}{0} & \colorbox{blue!10}{-2}\\
            3 & 1 & 1
        \end{bmatrix}
        \begin{bmatrix}
            \colorbox{blue!10}{-2} & 1 & 0\\
            \colorbox{blue!10}{-2} & 2 & 1\\
            \colorbox{blue!10}{0} & 0 & 3
        \end{bmatrix} = 
        \begin{bmatrix}
            14 & 12 & 11\\
            \colorbox{blue!10}{-2} &  & \\
            &  & 
        \end{bmatrix}$$
        
        $$\cdots$$
    \end{frame}
    
    % ----------- Producto matricial 07 ---------
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        Recordemos cómo opera el producto matricial:
        
        $$\begin{bmatrix}
            2 & 5 & 2\\
            1 & 0 & -2\\
            3 & 1 & 1
        \end{bmatrix}
        \begin{bmatrix}
            -2 & 1 & 0\\
            -2 & 2 & 1\\
            0 & 0 & 3
        \end{bmatrix} = 
        \begin{bmatrix}
            14 & 12 & 11\\
            -2 & 1 & -6\\
            -8 & 5 & 4
        \end{bmatrix}$$
    \end{frame}
    
    % ----------- El Perceptrón 03 --------------
    \begin{frame}{El Perceptrón}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{bias}=[draw,shape=circle,minimum size=0.8cm,fill=green!10]
                \tikzstyle{weight}=[draw,shape=rectangle,minimum size=0.5cm,fill=gray!20]
                \tikzstyle{sum}=[draw,shape=circle,minimum size=1cm,fill=yellow!20]
                \tikzstyle{activation}=[draw,shape=rectangle,minimum size=0.5cm,fill=blue!20]
                \tikzstyle{output}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]
                
                
                \node[unit](x1) at (-1.5,2.5){$x_1$};
                \node[unit](x2) at (-1.5,1.5){$x_2$};
                \node(dots) at (-1.5,0.75){\vdots};
                \node[unit](xn) at (-1.5,-0.25){$x_n$};
                \node[bias](b) at (-1.5,-1.25){$b$};
                
                
                \node[weight](w1) at (0.25,2.5){$w_1$};
                \node[weight](w2) at (0.25,1.5){$w_2$};
                \node[weight](wn) at (0.25,-0.25){$w_n$};
                \node[weight](wb) at (0.25,-1.25){$1$};
                
                \node[sum](p) at (2,1){$\Sigma$};
                \node[activation](a) at (3.5,1){$f$};
                \node[output](o) at (5,1){$\hat{y}$};
                
                \draw (x1) -- (w1);
                \draw (x2) -- (w2);
                \draw (xn) -- (wn);
                \draw (b) -- (wb);
                \draw[->] (w1) -- (p);
                \draw[->] (w2) -- (p);
                \draw[->] (wn) -- (p);
                \draw[->] (wb) -- (p);
                \draw[->] (p) -- (a);
                \draw[->] (a) -- (o);
            \end{tikzpicture}
            \vspace{10pt}
            $$\hat{y} = f\left(\displaystyle\sum_{i}^{n}w_ix_i + b\right)$$
        \end{center}
    \end{frame}
    
    % ----------- El Perceptrón 04 --------------
    \begin{frame}{El Perceptrón}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{bias}=[draw,shape=circle,minimum size=0.8cm,fill=green!10]
                \tikzstyle{weight}=[draw,shape=rectangle,minimum size=0.5cm,fill=gray!20]
                \tikzstyle{sum}=[draw,shape=circle,minimum size=1cm,fill=yellow!20]
                \tikzstyle{activation}=[draw,shape=rectangle,minimum size=0.5cm,fill=blue!20]
                \tikzstyle{output}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]
                
                
                \node[unit](x1) at (-1.5,2.5){$x_1$};
                \node[unit](x2) at (-1.5,1.5){$x_2$};
                \node(dots) at (-1.5,0.75){\vdots};
                \node[unit](xn) at (-1.5,-0.25){$x_n$};
                \node[bias](b) at (-1.5,-1.25){$b$};
                
                
                \node[weight](w1) at (0.25,2.5){$w_1$};
                \node[weight](w2) at (0.25,1.5){$w_2$};
                \node[weight](wn) at (0.25,-0.25){$w_n$};
                \node[weight](wb) at (0.25,-1.25){$1$};
                
                \node[sum](p) at (2,1){$\Sigma$};
                \node[activation](a) at (3.5,1){$f$};
                \node[output](o) at (5,1){$\hat{y}$};
                
                \draw (x1) -- (w1);
                \draw (x2) -- (w2);
                \draw (xn) -- (wn);
                \draw (b) -- (wb);
                \draw[->] (w1) -- (p);
                \draw[->] (w2) -- (p);
                \draw[->] (wn) -- (p);
                \draw[->] (wb) -- (p);
                \draw[->] (p) -- (a);
                \draw[->] (a) -- (o);
            \end{tikzpicture}
            \vspace{10pt}
            $$\displaystyle\sum_{i}^{n}w_ix_i = w_1x_1 + w_2x_2 + \cdots + w_nx_n$$
        \end{center}
    \end{frame}
    
    % ----------- El Perceptrón 05 --------------
    \begin{frame}{El Perceptrón}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{bias}=[draw,shape=circle,minimum size=0.8cm,fill=green!10]
                \tikzstyle{weight}=[draw,shape=rectangle,minimum size=0.5cm,fill=gray!20]
                \tikzstyle{sum}=[draw,shape=circle,minimum size=1cm,fill=yellow!20]
                \tikzstyle{activation}=[draw,shape=rectangle,minimum size=0.5cm,fill=blue!20]
                \tikzstyle{output}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]
                
                
                \node[unit](x1) at (-1.5,2.5){$x_1$};
                \node[unit](x2) at (-1.5,1.5){$x_2$};
                \node(dots) at (-1.5,0.75){\vdots};
                \node[unit](xn) at (-1.5,-0.25){$x_n$};
                \node[bias](b) at (-1.5,-1.25){$b$};
                
                
                \node[weight](w1) at (0.25,2.5){$w_1$};
                \node[weight](w2) at (0.25,1.5){$w_2$};
                \node[weight](wn) at (0.25,-0.25){$w_n$};
                \node[weight](wb) at (0.25,-1.25){$1$};
                
                \node[sum](p) at (2,1){$\Sigma$};
                \node[activation](a) at (3.5,1){$f$};
                \node[output](o) at (5,1){$\hat{y}$};
                
                \draw (x1) -- (w1);
                \draw (x2) -- (w2);
                \draw (xn) -- (wn);
                \draw (b) -- (wb);
                \draw[->] (w1) -- (p);
                \draw[->] (w2) -- (p);
                \draw[->] (wn) -- (p);
                \draw[->] (wb) -- (p);
                \draw[->] (p) -- (a);
                \draw[->] (a) -- (o);
            \end{tikzpicture}
            \vspace{10pt}
            $$\mathbf{w^{T}}\mathbf{x} = [w_1 w_2 \cdots w_n] \begin{bmatrix}
                x_1 \\
                x_2 \\
                \vdots \\
                x_n \\
            \end{bmatrix} = w_1x_1 + w_2x_2 + \cdots + w_nx_n$$
        \end{center}
    \end{frame}
    
    % ----------- Producto matricial 08 ---------
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{nns-01}
        \end{figure}
    \end{frame}
    
    % ----------- Producto matricial 09 ---------
    \begin{frame}{Producto matricial}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{nns-02}
        \end{figure}
    \end{frame}
    
    % --------- Composición de funciones 01 -----
    \begin{frame}{Composición de funciones}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{nns-03}
        \end{figure}
    \end{frame}
    
    % --------- Composición de funciones 02 -----
    \begin{frame}{Composición de funciones}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=1\textwidth]{nns-04}
        \end{figure}
    \end{frame}

    % --------- Funciones de activación ---------
    \begin{frame}{Funciones de activación}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{activation-functions}
            $$f(x) = \sigma(x) = \dfrac{1}{1 + e^{-x}} \Rightarrow f'(x) = f(x)(1 - f(x))$$
            $$f(x) = tanh(x) = \dfrac{e^x - e^{-x}}{e^x + e^{-x}} \Rightarrow f'(x) = 1 - f(x)^2$$
        \end{figure}
    \end{frame}
    
    % ----------- El Perceptrón Multicapa 01 ----
    \begin{frame}{El perceptrón multicapa}{Intro al aprendizaje profundo}
        \colorlet{myred}{red!80!black}
        \colorlet{myblue}{blue!80!black}
        \colorlet{mygreen}{green!60!black}
        \colorlet{mydarkred}{myred!40!black}
        \colorlet{mydarkblue}{myblue!40!black}
        \colorlet{mydarkgreen}{mygreen!40!black}
        \tikzstyle{node}=[very thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6]
        \tikzstyle{connect}=[->,thick,mydarkblue,shorten >=1]
        \tikzset{ % node styles, numbered for easy mapping with \nstyle
            node 1/.style={node,mydarkgreen,draw=mygreen,fill=mygreen!25},
            node 2/.style={node,mydarkblue,draw=myblue,fill=myblue!20},
            node 3/.style={node,mydarkred,draw=myred,fill=myred!20},
        }
        \def\nstyle{int(\lay<\Nnodlen?min(2,\lay):3)} % map layer number onto 1, 2, or 3
        
        \begin{center}
            \begin{tikzpicture}[x=2.4cm,y=1	.2cm]
                \readlist\Nnod{4,3,2} % array of number of nodes per layer
                \readlist\Nstr{n,m,k} % array of string number of nodes per layer
                \readlist\Cstr{x,h^{(\prev)},y} % array of coefficient symbol per layer
                \def\yshift{0.55} % shift last node for dots
                
                % LOOP over LAYERS
                \foreachitem \N \in \Nnod{
                    \def\lay{\Ncnt} % alias of index of current layer
                    \pgfmathsetmacro\prev{int(\Ncnt-1)} % number of previous layer
                    \foreach \i [evaluate={\c=int(\i==\N); \y=\N/2-\i-\c*\yshift;
                        \x=\lay; \n=\nstyle;
                        \index=(\i<\N?int(\i):"\Nstr[\n]");}] in {1,...,\N}{ % loop over nodes
                        % NODES
                        \node[node \n] (N\lay-\i) at (\x,\y) {$\strut\Cstr[\n]_{\index}$};
                        
                        % CONNECTIONS
                        \ifnumcomp{\lay}{>}{1}{ % connect to previous layer
                            \foreach \j in {1,...,\Nnod[\prev]}{ % loop over nodes in previous layer
                                \draw[white,line width=1.2,shorten >=1] (N\prev-\j) -- (N\lay-\i);
                                \draw[connect] (N\prev-\j) -- (N\lay-\i);
                            }
                            \ifnum \lay=\Nnodlen
                            \draw[connect] (N\lay-\i) --++ (0.5,0); % arrows out
                            \fi
                        }{
                            \draw[connect] (0.5,\y) -- (N\lay-\i); % arrows in
                        }
                        
                    }
                    \path (N\lay-\N) --++ (0,1+\yshift) node[midway,scale=1.6] {$\vdots$}; % dots
                }
                
                % LABELS
                \node[above=0.25,align=center,mydarkgreen] at (N1-1.90) {Capa de \\[-0.2em]entrada};
                \node[above=0.25,align=center,mydarkblue] at (N2-1.90) {Capas\\[-0.2em]ocultas};
                \node[above=0.25,align=center,mydarkred] at (N\Nnodlen-1.90) {Capa de\\[-0.2em]salida};
                
            \end{tikzpicture}
        \end{center}
    \end{frame}
    
    % ----------- El Perceptrón Multicapa 01 ----
    \begin{frame}{El perceptrón multicapa}{Intro al aprendizaje profundo}
        \tikzstyle{node}=[very thick,circle,draw=myblue,minimum size=22,inner sep=0.5,outer sep=0.6]
        \tikzstyle{connect}=[->,thick,mydarkblue,shorten >=1]
        \tikzset{ % node styles, numbered for easy mapping with \nstyle
            node 1/.style={node,mydarkgreen,draw=mygreen,fill=mygreen!25},
            node 2/.style={node,mydarkblue,draw=myblue,fill=myblue!20},
            node 3/.style={node,mydarkred,draw=myred,fill=myred!20},
        }
        \def\nstyle{int(\lay<\Nnodlen?min(2,\lay):3)} % map layer number onto 1, 2, or 3
        \begin{center}
            \begin{tikzpicture}[x=2.4cm,y=1	.2cm]
                \readlist\Nnod{3,3,1} % array of number of nodes per layer
                \readlist\Nstr{n,m,1} % array of string number of nodes per layer
                \readlist\Cstr{x,h^{(\prev)},y} % array of coefficient symbol per layer
                \def\yshift{0.55} % shift last node for dots
                
                % LOOP over LAYERS
                \foreachitem \N \in \Nnod{
                    \def\lay{\Ncnt} % alias of index of current layer
                    \pgfmathsetmacro\prev{int(\Ncnt-1)} % number of previous layer
                    \foreach \i [evaluate={\c=int(\i==\N); \y=\N/2-\i-\c*\yshift;
                        \x=\lay; \n=\nstyle;
                        \index=(\i<\N?int(\i):"\Nstr[\n]");}] in {1,...,\N}{ % loop over nodes
                        % NODES
                        \node[node \n] (N\lay-\i) at (\x,\y) {$\strut\Cstr[\n]_{\index}$};
                        
                        % CONNECTIONS
                        \ifnumcomp{\lay}{>}{1}{ % connect to previous layer
                            \foreach \j in {1,...,\Nnod[\prev]}{ % loop over nodes in previous layer
                                \draw[white,line width=1.2,shorten >=1] (N\prev-\j) -- (N\lay-\i);
                                \draw[connect] (N\prev-\j) -- (N\lay-\i);
                            }
                            \ifnum \lay=\Nnodlen
                            \draw[connect] (N\lay-\i) --++ (0.5,0); % arrows out
                            \fi
                        }{
                            \draw[connect] (0.5,\y) -- (N\lay-\i); % arrows in
                        }
                        
                    }
                    \path (N\lay-\N) --++ (0,1+\yshift) node[midway,scale=1.6] {$\vdots$}; % dots
                }
                
                % LABELS
                \node[above=0.25,align=center,mydarkgreen] at (N1-1.90) {Capa de \\[-0.2em]entrada};
                \node[above=0.25,align=center,mydarkblue] at (N2-1.90) {Capas\\[-0.2em]ocultas};
                \node[above=0.25,align=center,mydarkred] at (N\Nnodlen-1.90) {Capa de\\[-0.2em]salida};
            \end{tikzpicture}
            \vspace{10pt}\\
            Para $\mathbf{x}^{(i)}=(x^{(i)}_1, x^{(i)}_2, \dots, x^{(i)}_n)$, $y^{(i)}$, tendríamos que la salida es $\hat{y}^{(i)}_1 = f(x^{(i)})$. 
        \end{center}
    \end{frame}
    
    % ----------- Aprendizaje 01 ----------------
    \subsection{Aprendizaje}
    \begin{frame}{Cuantificación del error}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item La \textbf{función de pérdida (\textit{loss})} de nuestra red neuronal \textit{mide} el \textit{costo} asociado a predicciones incorrectas.
            \item Si observaciones (de entrada y salida) $(x^{(i)}, y^{(i)})$ y consideramos a la salida como función de $x^{(i)}$ y $\mathbf{W}$, entonces las salidas son $\hat{y} = f(x^{(i)}; \mathbf{W})$ y la función de pérdida puede escribirse como:
            $$\mathcal{L}(f(x^{(i)}; \mathbf{W}), y^{(i)})$$
            Es decir, una función que mida la salida \textit{real} con la \textit{predicción}.
            \underline{Todo esto para una observación $i$.}
        \end{itemize}
    \end{frame}
    
    % ----------- Aprendizaje 02 ----------------
    \begin{frame}{Cuantificación del error}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item Para todas las observaciones:
            $$\mathbf{J(W)} = \displaystyle \dfrac{1}{n}\sum_{i=1}^n \mathcal{L}(f(x^{(i)}; \mathbf{W}), y^{(i)})$$
            A esta función se le conoce como función de costo o función objetivo (lo que queremos minimizar).
        \end{itemize}
    \end{frame}
    
    % ----------- Aprendizaje 03 ----------------
    \begin{frame}{Algunos ejemplos}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item \textit{\textbf{Binary Cross Entropy Loss}}:
            Se puede utilizar con modelos que devuelven como salida una probabilidad entre 0 y 1.
            $$\mathbf{J(W)} = \displaystyle \dfrac{1}{n}\sum_{i=1}^n y^{(i)} \log(f(x^{(i)}; \mathbf{W})) + (1 - y^{(i)}) \log(1 - f(x^{(i)}; \mathbf{W}))$$
            \item \textit{\textbf{Mean Squared Error (MSE) Loss}}:
            Se puede utilizar con modelos de regresión que generan números reales continuos.
            $$\mathbf{J(W)} = \displaystyle \dfrac{1}{n}\sum_{i=1}^n \left( y^{(i)} - f(x^{(i)}; \mathbf{W})\right)^2$$
        \end{itemize}
    \end{frame}
    
    % ----------- Aprendizaje 03 ----------------
    \begin{frame}{Optimización del error}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item Queremos encontrar los pesos ideales de la red neuronal, los cuales minimizan $\mathbf{J(W)}$, es decir:
            $$\mathbf{W^*} = \displaystyle \operatorname*{argmin}_\mathbf{W} \dfrac{1}{n}\sum_{i=1}^n \mathcal{L}(f(x^{(i)}; \mathbf{W}), y^{(i)})$$
            $$\mathbf{W^*} = \displaystyle \operatorname*{argmin}_\mathbf{W} \mathbf{J(W)}$$
        \end{itemize}
    \end{frame}
    
    % ----------- Aprendizaje 04 ----------------
    \begin{frame}{Descenso de gradiente}{Intro al aprendizaje profundo}
        \begin{block}{Algoritmo: Descenso de gradiente}
            \begin{enumerate}
                \item Inicializar los pesos aleatoriamente $\sim \mathcal{N}(0,\sigma^2)$
                \item Repetir hasta converger:
                \item \hspace*{8pt} Calcular el gradiente $\dfrac{\partial \mathbf{J(W)}}{\partial \mathbf{W}}$
                \item \hspace*{8pt} Actualizar los pesos $\mathbf{W} \leftarrow \mathbf{W} - \eta \dfrac{\partial \mathbf{J(W)}}{\partial \mathbf{W}}$
                \item Devolver pesos \textit{óptimos}
            \end{enumerate}
        \end{block}
    \end{frame}
    
    % ----------- Aprendizaje 05 ----------------
    \begin{frame}{Retropropagación}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit1}=[draw,shape=circle,minimum size=0.8cm,fill=blue!20]
                \tikzstyle{unit2}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{unit3}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]                
                
                \node[unit1](x) at (-2.5,0){$x$};
                \node[unit2](z1) at (0,0){$z_1$};
                \node[unit3](yhat) at (2.5,0){$\hat{y}$};
                
                
                \draw[->] (x) -- (z1);
                \draw[->] (z1) -- (yhat);
                
                \draw [decorate,xshift=-4pt,yshift=0pt] (-1.25,0) -- (-1.25,0) node [black,midway,yshift=+0.25cm]{$w_1$};
                \draw [decorate,xshift=-4pt,yshift=0pt] (1.25,0) -- (1.25,0) node [black,midway,yshift=+0.25cm]{$w_2$};
                
                \draw[->] (yhat) -- (4.5,0)[xshift=15]node{$\mathbf{J(W)}$};
            \end{tikzpicture}
            \vspace{15pt}
            
            ¿Cómo se calculan los gradientes?\\
            Con la regla de la cadena.
        \end{center}
    \end{frame}
    
    % ----------- Aprendizaje 06 ----------------
    \begin{frame}{Retropropagación}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit1}=[draw,shape=circle,minimum size=0.8cm,fill=blue!20]
                \tikzstyle{unit2}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{unit3}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]                
                
                \node[unit1](x) at (-2.5,0){$x$};
                \node[unit2](z1) at (0,0){$z_1$};
                \node[unit3](yhat) at (2.5,0){$\hat{y}$};
                
                
                \draw[->] (x) -- (z1);
                \draw[->] (z1) -- (yhat);
                
                \draw [decorate,xshift=-4pt,yshift=0pt] (-1.25,0) -- (-1.25,0) node [black,midway,yshift=+0.25cm]{$w_1$};
                \draw [decorate,xshift=-4pt,yshift=0pt] (1.25,0) -- (1.25,0) node [black,midway,yshift=+0.25cm]{\colorbox{yellow!20}{$w_2$}};
                
                \draw[->] (yhat) -- (4.5,0)[xshift=15]node{$\mathbf{J(W)}$};
            \end{tikzpicture}
            \vspace{10pt}
            
            $$\dfrac{\partial \mathbf{J(W)}}{\partial \colorbox{yellow!20}{$w_2$} } = \dfrac{\partial \mathbf{J(W)}}{\partial \hat{y}} \cdot \dfrac{\partial \hat{y}}{\partial \colorbox{yellow!20}{$w_2$}}$$
        \end{center}
    \end{frame}
    
    % ----------- Aprendizaje 07 ----------------
    \begin{frame}{Retropropagación}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit1}=[draw,shape=circle,minimum size=0.8cm,fill=blue!20]
                \tikzstyle{unit2}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{unit3}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]                
                
                \node[unit1](x) at (-2.5,0){$x$};
                \node[unit2](z1) at (0,0){$z_1$};
                \node[unit3](yhat) at (2.5,0){$\hat{y}$};
                
                
                \draw[->] (x) -- (z1);
                \draw[->] (z1) -- (yhat);
                
                \draw [decorate,xshift=-4pt,yshift=0pt] (-1.25,0) -- (-1.25,0) node [black,midway,yshift=+0.25cm]{\colorbox{yellow!20}{$w_1$}};
                \draw [decorate,xshift=-4pt,yshift=0pt] (1.25,0) -- (1.25,0) node [black,midway,yshift=+0.25cm]{$w_2$};
                
                \draw[->] (yhat) -- (4.5,0)[xshift=15]node{$\mathbf{J(W)}$};
            \end{tikzpicture}
            \vspace{10pt}
            
            $$\dfrac{\partial \mathbf{J(W)}}{\partial \colorbox{yellow!20}{$w_1$} } = \dfrac{\partial \mathbf{J(W)}}{\partial \hat{y}} \cdot \dfrac{\partial \hat{y}}{\partial \colorbox{yellow!20}{$w_1$}}$$
        \end{center}
    \end{frame}
    
    % ----------- Aprendizaje 08 ----------------
    \begin{frame}{Retropropagación}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit1}=[draw,shape=circle,minimum size=0.8cm,fill=blue!20]
                \tikzstyle{unit2}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{unit3}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]                
                
                \node[unit1](x) at (-2.5,0){$x$};
                \node[unit2](z1) at (0,0){$z_1$};
                \node[unit3](yhat) at (2.5,0){$\hat{y}$};
                
                
                \draw[->] (x) -- (z1);
                \draw[->] (z1) -- (yhat);
                
                \draw [decorate,xshift=-4pt,yshift=0pt] (-1.25,0) -- (-1.25,0) node [black,midway,yshift=+0.25cm]{\colorbox{yellow!20}{$w_1$}};
                \draw [decorate,xshift=-4pt,yshift=0pt] (1.25,0) -- (1.25,0) node [black,midway,yshift=+0.25cm]{$w_2$};
                
                \draw[->] (yhat) -- (4.5,0)[xshift=15]node{$\mathbf{J(W)}$};
            \end{tikzpicture}
            \vspace{10pt}
            
            $$\dfrac{\partial \mathbf{J(W)}}{\partial \colorbox{yellow!20}{$w_1$} } = \dfrac{\partial \mathbf{J(W)}}{\partial \hat{y}} \cdot \dfrac{\partial \hat{y}}{\partial z_1 } \cdot \dfrac{\partial z_1}{\partial \colorbox{yellow!20}{$w_1$}}$$
        \end{center}
    \end{frame}
    
    % ----------- Aprendizaje 09 ----------------
    \begin{frame}{Retropropagación}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{tikzpicture}[shorten >=1pt]
                \tikzstyle{unit1}=[draw,shape=circle,minimum size=0.8cm,fill=blue!20]
                \tikzstyle{unit2}=[draw,shape=circle,minimum size=0.8cm,fill=green!20]
                \tikzstyle{unit3}=[draw,shape=circle,minimum size=0.8cm,fill=purple!20]                
                
                \node[unit1](x) at (-2.5,0){$x$};
                \node[unit2](z1) at (0,0){$z_1$};
                \node[unit3](yhat) at (2.5,0){$\hat{y}$};
                
                
                \draw[->] (x) -- (z1);
                \draw[->] (z1) -- (yhat);
                
                \draw [decorate,xshift=-4pt,yshift=0pt] (-1.25,0) -- (-1.25,0) node [black,midway,yshift=+0.25cm]{$w_1$};
                \draw [decorate,xshift=-4pt,yshift=0pt] (1.25,0) -- (1.25,0) node [black,midway,yshift=+0.25cm]{$w_2$};
                
                \draw[->] (yhat) -- (4.5,0)[xshift=15]node{$\mathbf{J(W)}$};
            \end{tikzpicture}
            \vspace{15pt}
            
            ¿Cómo se calculan los gradientes?\\
            Con la regla de la cadena.\\
            
            Esto se repite para \textbf{cada peso} en la red neuronal, usando los gradientes de las capas posteriores.
        \end{center}
    \end{frame}
    
    % --------- Learning rate -------------------
    \begin{frame}{Learning rate}{Intro al aprendizaje profundo}
        \begin{center}
            La actualización de pesos está dada por:
            $$\mathbf{W} \leftarrow \mathbf{W} - \colorbox{yellow!20}{$\eta$} \dfrac{\partial \mathbf{J(W)}}{\partial \mathbf{W}}$$
            \begin{figure}
                \centering
                \includegraphics[width=0.8\textwidth]{lr}
            \end{figure}
        \end{center}
    \end{frame}
    
    % ----------- Aprendizaje 10 ----------------
    \begin{frame}{Descenso de gradiente}{Intro al aprendizaje profundo}
        \begin{block}{Algoritmo: Descenso de gradiente}
            \begin{enumerate}
                \item Inicializar los pesos aleatoriamente $\sim \mathcal{N}(0,\sigma^2)$
                \item Repetir hasta converger:
                \item \hspace*{8pt} Calcular el gradiente \colorbox{yellow!20}{$\dfrac{\partial \mathbf{J(W)}}{\partial \mathbf{W}}^*$}
                \item \hspace*{8pt} Actualizar los pesos $\mathbf{W} \leftarrow \mathbf{W} - \eta \dfrac{\partial \mathbf{J(W)}}{\partial \mathbf{W}}$
                \item Devolver pesos \textit{óptimos}
            \end{enumerate}
        \end{block}
        \begin{itemize}
            \item $^*$Esto es muy pesado de calcular (computacionalmente).
        \end{itemize}
    \end{frame}
    
    % ----------- Aprendizaje 11 ----------------
    \begin{frame}{Descenso de gradiente estocástico}{Intro al aprendizaje profundo}
        \begin{block}{Algoritmo: Descenso de gradiente estocástico}
            \begin{enumerate}
                \item Inicializar los pesos aleatoriamente $\sim \mathcal{N}(0,\sigma^2)$
                \item Repetir hasta converger:
                \item \hspace*{8pt} Seleccionar observación $i$
                \item \hspace*{8pt} Calcular el gradiente \colorbox{yellow!20}{$\dfrac{\partial \mathbf{J_i(W)}}{\partial \mathbf{W}}^*$}
                \item \hspace*{8pt} Actualizar los pesos $\mathbf{W} \leftarrow \mathbf{W} - \eta \dfrac{\partial \mathbf{J(W)}}{\partial \mathbf{W}}$
                \item Devolver pesos \textit{óptimos}
            \end{enumerate}
        \end{block}
        \begin{itemize}
            \item $^*$Esto es muy sencillo de calcular (computacionalmente), pero es estocástico.
        \end{itemize}
    \end{frame}
    
    % ----------- Aprendizaje 12 ----------------
    \begin{frame}{Descenso de gradiente estocástico}{Intro al aprendizaje profundo}
        \begin{block}{Algoritmo: Descenso de gradiente estocástico - \textit{Mini batches}}
            \begin{enumerate}
                \item Inicializar los pesos aleatoriamente $\sim \mathcal{N}(0,\sigma^2)$
                \item Repetir hasta converger:
                \item \hspace*{8pt} Seleccionar un batch $B$ de observaciones
                \item \hspace*{8pt} Calcular el gradiente \colorbox{yellow!20}{$\dfrac{\partial \mathbf{J(W)}}{\partial \mathbf{W}} = \frac{1}{B} \sum_{k=1}^B \dfrac{\partial \mathbf{J_k(W)}}{\partial \mathbf{W}}^*$}
                \item \hspace*{8pt} Actualizar los pesos $\mathbf{W} \leftarrow \mathbf{W} - \eta \dfrac{\partial \mathbf{J(W)}}{\partial \mathbf{W}}$
                \item Devolver pesos \textit{óptimos}
            \end{enumerate}
        \end{block}
        \begin{itemize}
            \item $^*$Esto es rápido de calcular (computacionalmente), y da una mejor estimación del gradiente.
        \end{itemize}
    \end{frame}
    
    % ----------- Observaciones 02 ----------------
    \begin{frame}{Observaciones}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item Los \textbf{frameworks} para aprendizaje profundo (como TensorFlow, PyTorch, etc.) ya hacen la diferenciación y optimización por nosotros, es decir, ya calculan el gradiente y actualizan los pesos.
            \item Nosotros exploraremos el uso de \textbf{TensorFlow} a través de su API de alto nivel, \textbf{Keras}, para las redes neuronales que estaremos construyendo.
            \item Comenzaremos retomando algunos de los problemas planteados en la sesión anterior.
        \end{itemize}
    \end{frame}
    
    % ----------- TensorFlow --------------------
    \begin{frame}{TensorFlow}{Intro al aprendizaje profundo}
        \begin{center}
            \begin{figure}
                \centering
                \includegraphics[width=0.5\textwidth]{tf}
            \end{figure}
            \colorbox{blue!10}{\href{https://www.tensorflow.org/}{TensorFlow}} es un framework open-source para Machine Learning desarrollado por Google. Utilizado para construir y entrenar redes neuronales artificiales.
        \end{center}
    \end{frame}
    
    % ----------- Ejercicio 02 ------------------
    \begin{frame}{Ejercicio}{Intro al aprendizaje profundo}
        \begin{center}
            {\Large \textbf{Ejercicio: Exploración del TensorFlow Playground}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.65\textwidth]{tf-playground}
        \end{figure}
    \end{frame}
    
    % ----------- Ejercicio 03 ------------------
    \begin{frame}{Ejercicio}{Intro al aprendizaje profundo}
        \begin{center}
            {\Large \textbf{Ejercicio: Problema de separabilidad lineal}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.7\textwidth]{xor}
        \end{figure}
    \end{frame}
    
    % ----------- Ejercicio 04 ------------------
    \begin{frame}{Ejercicio}{Intro al aprendizaje profundo}
        \begin{center}
            {\Large \textbf{Ejercicio: Exploración con TensorFlow}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\textwidth]{tf}
        \end{figure}
    \end{frame}
    
    % ----------- Lecturas recomendadas 02 ------
    \begin{frame}{Lecturas recomendadas}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item Setting the   \colorbox{blue!10}{\href{https://www.jeremyjordan.me/nn-learning-rate/}{learning rate}} of your neural network
            \item \colorbox{blue!10}{\href{https://hmkcode.com/ai/backpropagation-step-by-step/}{Retropropagación}} paso a paso
            \item \colorbox{blue!10}{\href{https://www.tensorflow.org/tutorials}{TensorFlow Tutorials}}
            \item Libro \colorbox{blue!10}{\href{http://neuralnetworksanddeeplearning.com/}{Neural Networks and Deep Learning}}
        \end{itemize}
    \end{frame}
    
    % ----------- Regularización 01 --------------
    \subsection{Regularización}
    
    \begin{frame}{El problema del overfitting}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.85\textwidth]{overfitting}
        \end{figure}
    \end{frame}
    
    % ----------- Regularización 02 --------------
    \begin{frame}{Regularización}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item La \textbf{regularización} consiste en alguna técnica que sirve para evitar que un modelo se sobreajuste.
            \item Es necesaria porque ayuda a mejorar la generalización de nuestro modelo con datos no vistos.
            \item Los métodos de regularización que exploraremos serán:
            \begin{itemize}
                \item \textit{Dropout}
                \item \textit{Early stopping}
            \end{itemize}
        \end{itemize}
    \end{frame}
    
    % ----------- Dropout 01 ---------------------
    \begin{frame}{Dropout}{Intro al aprendizaje profundo}
        \def\layersep{1}
        \def\nodesep{0.75}
        
        \begin{tikzpicture}[
            node/.style={circle, draw, thick},
            ]
            
            \foreach \y in {1,...,5}{
                \node[node] (i\y) at (0,\nodesep*\y) {};
                \node[node, right=\layersep of i\y] (h1\y) {};
                \node[node, right=\layersep of h1\y] (h2\y) {};
            }
            
            \node[node, right=\layersep of h22] (o1) {};
            \node[node, right=\layersep of h24] (o2) {};
            
            \foreach \source in {1,...,5}
            \foreach \dest in {1,...,5}{
                \path[-stealth, thick] (i\source) edge (h1\dest);
                \path[-stealth, thick] (h1\source) edge (h2\dest);
            }
            \foreach \source in {1,...,5}
            \foreach \dest in {1,2}
            \draw[-stealth, thick] (h2\source) -- (o\dest);
            
            \draw[-stealth, thick] (4.2,3*\nodesep) -- node[above,font=\bfseries]{dropout} (6, 3*\nodesep);
            
            % Boundary
            
            \foreach \y in {1,...,5}
            \node[node, right=10em of h2\y] (di\y) {};
            
            \node[red,font=\huge] at (di1) {$\times$};
            \node[red,font=\huge] at (di3) {$\times$};
            
            \foreach \y in {1,...,5}
            \node[node, right=\layersep of di\y] (dh1\y) {};
            
            \node[red,font=\huge] at (dh11) {$\times$};
            \node[red,font=\huge] at (dh13) {$\times$};
            \node[red,font=\huge] at (dh14) {$\times$};
            
            \foreach \y in {1,...,5}
            \node[node, right=\layersep of dh1\y] (dh2\y) {};
            
            \node[red,font=\huge] at (dh22) {$\times$};
            \node[red,font=\huge] at (dh24) {$\times$};
            
            \node[node, right=\layersep of dh22] (do1) {};
            \node[node, right=\layersep of dh24] (do2) {};
            
            \foreach \source in {2,4,5}
            \foreach \dest in {2,5}
            \draw[-stealth, thick] (di\source) -- (dh1\dest);
            
            \foreach \source in {2,5}
            \foreach \dest in {1,3,5}
            \draw[-stealth, thick] (dh1\source) -- (dh2\dest);
            
            \foreach \source in {1,3,5}
            \foreach \dest in {1,2}
            \draw[-stealth, thick] (dh2\source) -- (do\dest);
            
        \end{tikzpicture}
    \end{frame}
    
    % ----------- Dropout 02 ---------------------
    \begin{frame}{Dropout}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item Durante el entrenamiento, establecemos aleatoriamente algunas activaciones en 0
            \begin{itemize}
                \item Típicamente hacemos "drop" del 50\% de activaciones en una capa.
                \item Esto forza a la red a no depender de ningún nodo/neurona.
            \end{itemize}
            \item Podemos realizar el dropout en TensorFlow utilizando la capa \texttt{tf.keras.layers.Dropout(0.5)}, donde el 0.5 puede variar de acuerdo a lo especificado.
        \end{itemize}
    \end{frame}
    
    % ----------- Early stopping 01 --------------
    \begin{frame}{Early stopping}{Intro al aprendizaje profundo}
        \begin{figure}
            \centering
            \includegraphics[width=0.45\textwidth]{early-stop-01}
            \includegraphics[width=0.45\textwidth]{early-stop-02}
        \end{figure}
    \end{frame}
    
    % ----------- Early stopping 01 --------------
    \begin{frame}{Early stopping}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item El \textit{Early Stopping} puede ser realizado en TensorFlow de manera sencilla creando un callback (función que se llama en cada iteración durante el entrenamiento de la red neuronal):\\
        \end{itemize}
        
        \texttt{\\model = tf.keras.models.Sequential(...)}\\
        \texttt{callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)}\\
        \texttt{history = model.fit(..., callbacks=[callback])}
    \end{frame}
    
    % ----------- Lecturas recomendadas 03 ------
    \begin{frame}{Lecturas recomendadas}{Intro al aprendizaje profundo}
        \begin{itemize}
            \item \colorbox{blue!10}{\href{https://jmlr.org/papers/v15/srivastava14a.html}{Artículo}} "Dropout: A Simple Way to Prevent Neural Networks from Overfitting"
            \item \colorbox{blue!10}{\href{https://www.pinecone.io/learn/regularization-in-neural-networks/}{Regularización en Redes Neuronales}}
            \item \colorbox{blue!10}{\href{https://neptune.ai/blog/vanishing-and-exploding-gradients-debugging-monitoring-fixing}{Vanishing and Exploding Gradients in Neural Network Models:}} Debugging, Monitoring, and Fixing
        \end{itemize}
    \end{frame}
    
    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    
    % ----------- Computer Vision ----------------
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Visión computacional profunda}
    
    % ----------- Intro a imágenes 01 ------------
    \subsection{Introducción a imágenes}
    \begin{frame}{¿Qué es una imagen?}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.75\textwidth]{img-deer}
        \end{figure}
    \end{frame}
    
    % ----------- Intro a imágenes 02 ------------
    \begin{frame}{¿Qué es una imagen?}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.75\textwidth]{img-lincoln}
            \let\thefootnote\relax\footnote{{\tiny “Tutorial 1: Image Filtering.” AI Stanford. \url{https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html}}}
        \end{figure}
    \end{frame}
    
    % ----------- Intro a imágenes 03 ------------
    \begin{frame}{¿Qué es una imagen?}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.75\textwidth]{img-lena}
            \let\thefootnote\relax\footnote{{\tiny “Tutorial 1: Image Filtering.” AI Stanford. \url{https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html}}}
        \end{figure}
    \end{frame}
    
    % ----------- Intro a imágenes 04 ------------
    \begin{frame}{¿Qué es una imagen?}{Visión computacional profunda}
        \begin{itemize}
            \item Una imagen es un arreglo de pixeles, la cual puede tener 1 o más canales de color. Usualmente:
            \begin{itemize}
                \item 1 canal de color $\rightarrow$ Escala de grises
                \item 3 canales de color $\rightarrow$ Escala RGB
                \item 4 canales de color $\rightarrow$ Escala RGBA
            \end{itemize}
            \item Un pixel puede ser visto como un objeto 5-dimensional $(x, y, r, g, b)$.
        \end{itemize}
    \end{frame}
    
    % ----------- Biología humana 01 -------------
    \begin{frame}{La biología humana}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{img-encroma-01}
            \let\thefootnote\relax\footnote{{\tiny “How EnChroma Color Blind Glasses Work.” EnChroma. \url{http://enchroma.com/technology/}}}
        \end{figure}
    \end{frame}
    
    % ----------- Biología humana 02 -------------
    \begin{frame}{La biología humana}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.8\textwidth]{img-encroma-02}
            \let\thefootnote\relax\footnote{{\tiny “How EnChroma Color Blind Glasses Work.” EnChroma. \url{http://enchroma.com/technology/}}}
        \end{figure}
    \end{frame}
    
    % ----------- Espacios de color --------------
    \subsection{Espacios de color}
    \begin{frame}{Espacios de color}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{img-color-space}
        \end{figure}
    \end{frame}
    
    % ----------- Ejercicio 05 ------------------
    \begin{frame}{Ejercicio}{Intro al aprendizaje profundo}
        \begin{center}
            {\Large \textbf{Ejercicio: Introducción a imágenes}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\textwidth]{img-lena}
        \end{figure}
    \end{frame}
    
    % ----------- Convoluciones 01 ---------------
    \subsection{Convoluciones \& Pooling}
    \begin{frame}{¿Qué es una convolución?}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{1d-conv}
        \end{figure}
    \end{frame}
    
    % ----------- Convoluciones 02 ---------------
    \begin{frame}{¿Qué es una convolución?}{Visión computacional profunda}
        \begin{center}
            \begin{tikzpicture}[
                2d-arr/.style={matrix of nodes, row sep=-\pgflinewidth, column sep=-\pgflinewidth, nodes={draw}}, ampersand replacement=\&
              ]
                
                \matrix (mtr) [2d-arr] {
                    0 \& 1 \& 1 \& |[fill=orange!30]| 1 \& |[fill=orange!30]| 0 \& |[fill=orange!30]| 0 \& 0\\
                    0 \& 0 \& 1 \& |[fill=orange!30]| 1 \& |[fill=orange!30]| 1 \& |[fill=orange!30]| 0 \& 0\\
                    0 \& 0 \& 0 \& |[fill=orange!30]| 1 \& |[fill=orange!30]| 1 \& |[fill=orange!30]| 1 \& 0\\
                    0 \& 0 \& 0 \& 1 \& 1 \& 0 \& 0\\
                    0 \& 0 \& 1 \& 1 \& 0 \& 0 \& 0\\
                    0 \& 1 \& 1 \& 0 \& 0 \& 0 \& 0\\
                    1 \& 1 \& 0 \& 0 \& 0 \& 0 \& 0\\
                };
                
                \node[below=of mtr-5-4] {$\mathbf I$};
                
                \node[right=0.2em of mtr] (str) {$*$};
                
                \matrix (K) [2d-arr, right=0.2em of str, nodes={draw, fill=teal!30}] {
                    1 \& 0 \& 1 \\
                    0 \& 1 \& 0 \\
                    1 \& 0 \& 1 \\
                };
                \node[below=of K-3-2] {$\mathbf K$};
                
                \node[right=0.2em of K] (eq) {$=$};
                
                \matrix (ret) [2d-arr, right=0.2em of eq] {
                    1 \& 4 \& 3 \& |[fill=blue!80!black!30]| 4 \& 1\\
                    1 \& 2 \& 4 \& 3 \& 3\\
                    1 \& 2 \& 3 \& 4 \& 1\\
                    1 \& 3 \& 3 \& 1 \& 1\\
                    3 \& 3 \& 1 \& 1 \& 0\\
                };
                \node[below=of ret-4-3] {$\mathbf{I * K}$};
                
                \draw[dashed, teal] (mtr-1-6.north east) -- (K-1-1.north west);
                \draw[dashed, teal] (mtr-3-6.south east) -- (K-3-1.south west);
                
                \draw[dashed, blue!80!black] (K-1-3.north east) -- (ret-1-4.north west);
                \draw[dashed, blue!80!black] (K-3-3.south east) -- (ret-1-4.south west);
                
                \foreach \i in {1,2,3} {
                    \foreach \j in {4,5,6} {
                        \node[font=\tiny, scale=0.6, shift={(-1.2ex,-2ex)}] at (mtr-\i-\j) {$\times \pgfmathparse{int(mod(\i+\j,2))}\pgfmathresult$};
                    }
                }
                
            \end{tikzpicture}
        \end{center}
    \end{frame}
    
    % ----------- Convoluciones 03 ---------------
    \begin{frame}{¿Qué es una convolución?}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{filter}
        \end{figure}
        \let\thefootnote\relax\footnote{{\tiny “Image Kernels.” Victor Powell. \url{https://setosa.io/ev/image-kernels/}}}
    \end{frame}
    
    % ----------- Pooling 01 ---------------------
    \begin{frame}{Pooling}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{pooling}
        \end{figure}
    \end{frame}
    
    % ----------- Ejercicio 06 ------------------
    \begin{frame}{Ejercicio}{Intro al aprendizaje profundo}
        \begin{center}
            {\Large \textbf{Ejercicio: Convoluciones \& Pooling}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\textwidth]{filter}
        \end{figure}
    \end{frame}
    
    % ----------- CNNs 01 ------------------------
    \subsection{Redes neuronales convolucionales}
    \begin{frame}{Redes neuronales convolucionales}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{lecun}
            \caption{Yann LeCun}
        \end{figure}
    \end{frame}
    
    % ----------- CNNs 02 ------------------------
    \begin{frame}{Redes neuronales convolucionales}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{cnns-01}
        \end{figure}
    \end{frame}
    
    % ----------- CNNs 03 ------------------------
    \begin{frame}{Redes neuronales convolucionales}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{cnns-02}
        \end{figure}
    \end{frame}
    
    % ----------- CNNs 04 ------------------------
    \begin{frame}{Redes neuronales convolucionales}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{cnns-03}
        \end{figure}
    \end{frame}
    
    % ----------- CNNs 05 ------------------------
    \subsection{Clasificadores de imágenes (LeNet, VGG16, etc.)}
    \begin{frame}{LeNet-5}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{classifiers-01}
        \end{figure}
    \end{frame}
    
    % ----------- CNNs 06 ------------------------
    \begin{frame}{VGG16}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{classifiers-02}
        \end{figure}
    \end{frame}
    
    % ----------- CNNs 07 ------------------------
    \begin{frame}{Resnet50}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{classifiers-03}
        \end{figure}
    \end{frame}
    
    % ----------- CNNs 08 ------------------------
    \begin{frame}{GoogLeNet}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.9\textwidth]{classifiers-04}
        \end{figure}
    \end{frame}
    
    % ----------- Ejercicio 07 ------------------
    \begin{frame}{Ejercicio}{Intro al aprendizaje profundo}
        \begin{center}
            {\Large \textbf{Ejercicio: Redes neuronales convolucionales}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\textwidth]{classifiers-01}
        \end{figure}
    \end{frame}
    
    % ----------- Lecturas recomendadas 04 ------
    \begin{frame}{Lecturas recomendadas}{Visión computacional}
        \begin{itemize}
            \item Tutorial 1: \colorbox{blue!10}{\href{https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html}{Image Filtering}}
            \item \colorbox{blue!10}{\href{https://setosa.io/ev/image-kernels/}{Image Kernels Explained Visually}} by Victor Powell
            \item \colorbox{blue!10}{\href{https://gudgud96.github.io/2020/11/25/param-pooling/}{Parameterized Pooling Layers}} by Hao Hao Tan
            \item TensorFlow Tutorials: \colorbox{blue!10}{\href{https://www.tensorflow.org/tutorials/images}{Vision}}
            
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 01 ---------------
    \subsection{Autoencoders}
    \begin{frame}{Reconstrucción de imágenes}{Visión computacional profunda}
        \begin{itemize}
            \item Proceso de generar una imagen de salida a partir de una de entrada, generalmente con el objetivo de restaurar o mejorar la calidad de la imagen original.
            \item En el contexto de los autoencoders y la tarea de denoising, la reconstrucción implica generar una versión limpia y libre de ruido de una imagen ruidosa o de baja calidad.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 02 ---------------
    \begin{frame}{Reconstrucción de imágenes}{Visión computacional profunda}
        \begin{enumerate}
            \item Restauración de la calidad visual.
            \item Preservación de la información relevante.
            \item Mejora de aplicaciones y análisis (eliminación de ruido).
            \item Preservación de características y texturas.
            \item Calidad y experiencia visual.
        \end{enumerate}
    \end{frame}
    
    % ----------- Autoencoders 03 ---------------
    \begin{frame}{Aplicaciones}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.75\textwidth]{xray-denoise}
            \let\thefootnote\relax\footnote{{\tiny “Autoencoder For Denoising Images.” Michel Kana. \url{https://towardsdatascience.com/autoencoder-for-denoising-images-7d63a0831bfd}}}
        \end{figure}
    \end{frame}
    
    % ----------- Autoencoders 04 ---------------
    \begin{frame}{Autoencoders}{Visión computacional profunda}
        ANNs utilizadas para aprender representaciones eficientes de los datos de entrada sin necesidad de etiquetas o supervisión externa.
        \begin{figure}
            \centering
            \includegraphics[width=0.65\textwidth]{autoencoder-keras}
            \let\thefootnote\relax\footnote{{\tiny “Building Autoencoders in Keras.” Keras Blog. \url{https://blog.keras.io/building-autoencoders-in-keras.html}}}
        \end{figure}
    \end{frame}
    
    % ----------- Autoencoders 05 ---------------
    \begin{frame}{Estructura de un autoencoder}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=\textwidth]{autoencoder-architecture}
            \let\thefootnote\relax\footnote{{\tiny “From Autoencoder to Beta-VAE.” Lilian Weng. \url{https://lilianweng.github.io/posts/2018-08-12-vae/}}}
        \end{figure}
    \end{frame}
    
    % ----------- Autoencoders 06 ---------------
    \begin{frame}{Funcionamiento de autoencoders}{Visión computacional profunda}
        \begin{itemize}
            \item \textit{\textbf{Encoder:}} Toma los datos de entrada y los transforma en una representación de menor dimensionalidad, también conocida como representación latente. 
            \item \textbf{El objetivo del codificador es...} \\
            Comprimir la información esencial de los datos en esta representación latente. 
            \item \underline{Usualmente}, el codificador está compuesto por capas de neuronas que reducen gradualmente la dimensionalidad de los datos a medida que se propagan a través de la red. Este proceso de reducción dimensional es crucial para extraer las características más importantes de los datos y deshacerse de la información redundante o ruidosa.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 07 ---------------
    \begin{frame}{Funcionamiento de autoencoders}{Visión computacional profunda}
        \begin{itemize}
            \item \textit{\textbf{Decoder:}} Toma la representación latente generada y la reconstruye en una salida que se asemeja lo más posible a la entrada original. 
            \item \textbf{El objetivo del decodificador es...}\\ 
            Descomprimir la representación latente y generar una reconstrucción fiel de los datos de entrada.
            \item \underline{Al igual que el encoder}, el decodificador está compuesto por capas de neuronas, pero en este caso, las capas aumentan gradualmente la dimensionalidad de la representación latente hasta que se obtiene una salida de la misma dimensión que los datos de entrada originales.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 08 ---------------
    \begin{frame}{Funcionamiento de autoencoders}{Visión computacional profunda}
        \begin{itemize}
            \item La idea central es que, al restringir la capacidad de reconstrucción de la red, se obliga al codificador a aprender representaciones más compactas y significativas de los datos. 
            
            \item En otras palabras, se busca que el codificador capture las características más importantes y relevantes de los datos en la representación latente, mientras que el decodificador se encarga de reconstruir los datos de entrada a partir de esa representación latente.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 09 ---------------
    \begin{frame}{Estructura de un autoencoder}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=\textwidth]{autoencoder-architecture}
            \let\thefootnote\relax\footnote{{\tiny “From Autoencoder to Beta-VAE.” Lilian Weng. \url{https://lilianweng.github.io/posts/2018-08-12-vae/}}}
        \end{figure}
    \end{frame}
    
    % ----------- Autoencoders 10 ---------------
    \begin{frame}{Aplicaciones de los autoencoders}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.4\textwidth]{autoencoder-mini}
        \end{figure}
        \begin{itemize}
            \item \textbf{Denoising de imágenes:} Se utilizan para eliminar el ruido de las imágenes y reconstruir versiones más limpias.
            \item \textbf{Reducción de dimensionalidad:} Los autoencoders se utilizan para reducir la dimensionalidad de los datos, lo que facilita la visualización y comprensión de datos complejos. Esto es útil en análisis exploratorio de datos, visualización de datos de gran dimensión y clustering.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 11 ---------------
    \begin{frame}{Aplicaciones de los autoencoders}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.4\textwidth]{autoencoder-mini}
        \end{figure}
        \begin{itemize}
            \item \textbf{Generación de contenido:} Pueden generar contenido nuevo y original aprendiendo las características latentes de un conjunto de datos. Esto se utiliza en aplicaciones como la generación de imágenes sintéticas, la creación de música o la generación de texto.
            \item \textbf{Detección de anomalías:} Se utilizan para detectar patrones anormales o inusuales en los datos. Esto se aplica en áreas como la detección de fraudes en transacciones financieras, la detección de intrusiones en sistemas de seguridad o la detección de anomalías en imágenes médicas.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 11 ---------------
    \begin{frame}{Entrenamiento de autoencoders}{Visión computacional profunda}
        \begin{itemize}
            \item \textbf{Aprendizaje:} Durante el entrenamiento de los autoencoders, se utilizan pares de datos de entrada y salida correspondientes. 
            \item La red se entrena para \textbf{minimizar} la diferencia entre la entrada original y la salida reconstruida.
        \end{itemize}
    \end{frame}
    
    % ----------- Ejercicio 08 ------------------
    \begin{frame}{Ejercicio}{Visión computacional profunda}
        \begin{center}
            {\Large \textbf{Ejercicio: Autoencoder básico}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\textwidth]{autoencoder-keras}
        \end{figure}
    \end{frame}
    
    % ----------- Autoencoders 12 ---------------
    \begin{frame}{Limitantes}{Visión computacional profunda}
        \begin{itemize}
            \item \textbf{Incapacidad para capturar información espacial:} Los autoencoders básicos pueden tener dificultades para capturar la estructura espacial de las imágenes, ya que no tienen en cuenta la información de vecindad de los píxeles.
            \item \textbf{Sensibilidad a las transformaciones:} Pueden ser sensibles a las transformaciones geométricas, como la rotación o el desplazamiento de la imagen, lo que puede afectar su capacidad de reconstrucción.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 13 ---------------
    \begin{frame}{Limitantes}{Visión computacional profunda}
        \begin{itemize}
            \item \textbf{Autoencoders convolucionales como solución:} Son una variante de los autoencoders que incorporan capas convolucionales para abordar las limitaciones mencionadas.
            \item \textbf{Ventajas de los autoencoders convolucionales:} Mejoran con la capacidad para capturar algunas características espaciales, preservar la estructura y ser más robustos frente a transformaciones geométricas
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 14 ---------------
    \begin{frame}{Estructura de un autoencoder}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=\textwidth]{autoencoder-architecture}
            \let\thefootnote\relax\footnote{{\tiny “From Autoencoder to Beta-VAE.” Lilian Weng. \url{https://lilianweng.github.io/posts/2018-08-12-vae/}}}
        \end{figure}
    \end{frame}
    
    % ----------- Autoencoders 15 ---------------
    \begin{frame}{Estructura de un autoencoder}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.85\textwidth]{conv-autoencoder}
            \let\thefootnote\relax\footnote{{\tiny “IROS 2017: Feature discovery and visualization of robot mission data using convolutional autoencoders and Bayesian nonparametric topic modeling.” \url{https://warp.whoi.edu/iros2017/}}}
        \end{figure}
    \end{frame}
    
    % ----------- Autoencoders 16 ---------------
    \begin{frame}{Denoising autoencoder (DAE/DCAE)}{Visión computacional profunda}
        \begin{figure}
            \centering
            \includegraphics[width=0.7\textwidth]{dcae}
            \let\thefootnote\relax\footnote{{\tiny “Denoising autoencoder (DAE).” \url{https://subscription.packtpub.com/book/data/9781788629416/3/ch03lvl1sec19/denoising-autoencoder-dae}}}
        \end{figure}
    \end{frame}
    
    % ----------- Ejercicio 09 ------------------
    \begin{frame}{Ejercicio}{Visión computacional profunda}
        \begin{center}
            {\Large \textbf{Ejercicio: Autoencoder convolucional}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\textwidth]{conv-autoencoder}
        \end{figure}
    \end{frame}
    
    % ----------- Autoencoders 17 ---------------
    \subsection{Trabajos relacionados y avances recientes}
    
    \begin{frame}{Trabajos relacionados y avances recientes}{Visión computacional profunda}
        Han habido varios trabajos de investigación y avances recientes que han contribuido al desarrollo de nuevas arquitecturas, técnicas de entrenamiento mejoradas y aplicaciones emergentes.
        \begin{columns}
            \begin{column}{0.55\textwidth}
                \begin{itemize}
                    \item \textbf{UNet:} Es ampliamente utilizada en el campo de la segmentación de imágenes, pero también se ha aplicado con éxito en tareas de denoising.
                \end{itemize}
            \end{column}
            \begin{column}{0.4\textwidth}
                \begin{center}
                    \includegraphics[width=\textwidth]{unet-model}
                \end{center}
            \end{column}
        \end{columns}
    \end{frame}
    
    % ----------- Autoencoders 18 ---------------
    \begin{frame}{Trabajos relacionados y avances recientes}{Visión computacional profunda}
        \begin{columns}
            \begin{column}{0.55\textwidth}
                \begin{itemize}
                    \item \textbf{Variational Autoencoders (VAEs):} Los VAEs son una variante de los autoencoders que se utilizan para el aprendizaje de distribuciones latentes. Han demostrado ser efectivos en el denoising de imágenes al aprender representaciones latentes que siguen una distribución probabilística, lo que permite una generación más controlada y realista de imágenes limpias.
                \end{itemize}
            \end{column}
            \begin{column}{0.4\textwidth}
                \begin{center}
                    \includegraphics[width=\textwidth]{vae}
                \end{center}
            \end{column}
        \end{columns}
    \end{frame}
    
    % ----------- Autoencoders 19 ---------------
    \begin{frame}{Trabajos relacionados y avances recientes}{Visión computacional profunda}
        \begin{columns}
            \begin{column}{0.55\textwidth}
                \begin{itemize}
                    \item \textbf{Generative Adversarial Networks (GANs):} Estos modelos aprovechan la capacidad de los GANs para generar imágenes realistas y para aprender representaciones latentes eficientes. Los GANs han demostrado ser efectivos en el denoising y la generación de imágenes de alta calidad, entre otros.
                \end{itemize}
            \end{column}
            \begin{column}{0.4\textwidth}
                \begin{center}
                    \includegraphics[width=\textwidth]{gans-ae}
                \end{center}
            \end{column}
        \end{columns}
    \end{frame}
    
    % ----------- Autoencoders 20 ---------------
    \begin{frame}{Tareas en el campo de visión artificial}{Visión computacional profunda}
        \begin{itemize}
            \item \textbf{Clasificación de imágenes:} La tarea de clasificación de imágenes implica asignar una etiqueta o categoría a una imagen de entrada. Esto implica entrenar un modelo para reconocer y distinguir diferentes objetos, personas o escenas en una imagen.
            \item \textbf{Detección de objetos:} La detección de objetos implica localizar y clasificar múltiples objetos en una imagen. El objetivo es detectar la presencia y la ubicación de objetos específicos en una escena, a menudo utilizando cuadros delimitadores para delinear las regiones donde se encuentran los objetos.
            \item \textbf{Denoising o reconstrucción de imágenes:} Consiste en eliminar o reducir el ruido presente en una imagen, obteniendo una versión más limpia y clara. Esta tarea es relevante en áreas como la fotografía, la medicina y la seguridad.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 21 ---------------
    \begin{frame}{Tareas en el campo de visión artificial}{Visión computacional profunda}
        \begin{itemize}
            \item \textbf{Segmentación semántica:} La segmentación semántica implica asignar una etiqueta a cada píxel de una imagen para identificar y delimitar las diferentes regiones o objetos presentes. El objetivo es comprender la estructura y el contenido de una imagen a nivel de píxel.
            \item \textbf{Detección de rostros:} La detección de rostros es una tarea específica de la visión artificial que implica detectar y localizar los rostros en una imagen. Es ampliamente utilizado en aplicaciones de reconocimiento facial, análisis de emociones y sistemas de seguridad.
            \item \textbf{Reconocimiento y verificación facial:} El reconocimiento facial se refiere a la tarea de identificar y reconocer a una persona específica a partir de una imagen o secuencia de imágenes. La verificación facial se enfoca en verificar si una imagen de rostro coincide con una identidad específica.
        \end{itemize}
    \end{frame}
    
    % ----------- Autoencoders 22 ---------------
    \begin{frame}{Tareas en el campo de visión artificial}{Visión computacional profunda}
        \begin{itemize}
            \item \textbf{Estimación de pose:} La estimación de pose se refiere a la tarea de determinar la posición y orientación de un objeto o persona en una imagen. Esto implica detectar y rastrear las articulaciones o puntos clave en una imagen para comprender la postura y el movimiento.
            \item \textbf{Estimación de profundidad:} La estimación de profundidad implica inferir la información de la distancia o la profundidad de los objetos en una imagen. Es útil en aplicaciones de realidad virtual, conducción autónoma y sistemas de navegación.
            \item \textbf{Super-resolución:} La super-resolución se refiere a aumentar la resolución o la calidad de una imagen de baja resolución. El objetivo es generar una versión de alta resolución que capture más detalles y claridad.
        \end{itemize}
    \end{frame}
    
    % Mover/eliminar conforme se agregan los contenidos
    \section{Modelado profundo de secuencias}
    \section{Modelado generativo profundo}
    \section{Panorama actual y futuro}
    
    % ----------- Lecturas recomendadas 05 ------
    \begin{frame}{Lecturas recomendadas}{Visión computacional}
        \begin{itemize}
            \item \colorbox{blue!10}{\href{https://lilianweng.github.io/posts/2018-08-12-vae/}{From Autoencoder to Beta-VAE}}
            \item \colorbox{blue!10}{\href{https://blog.keras.io/building-autoencoders-in-keras.html}{Building Autoencoders in Keras}}
            \item \colorbox{blue!10}{\href{https://www.codificandobits.com/blog/autoencoders-explicacion-y-tutorial-python/}{Autoencoders: explicación y tutorial en Python}}
            \item \colorbox{blue!10}{\href{https://towardsdatascience.com/autoencoder-for-denoising-images-7d63a0831bfd}{Autoencoder For Denoising Images}}
            \item Medical image denoising using \colorbox{blue!10}{\href{https://arxiv.org/pdf/1608.04667}{convolutional denoising autoencoders}}
            
        \end{itemize}
    \end{frame}

    {
        \setbeamercolor{background canvas}{bg=}
        \includepdf[pages={1-11}]{unet.pdf}
    }
    
    % ----------- Ejercicio 10 ------------------
    \begin{frame}{Ejercicio}{Visión computacional profunda}
        \begin{center}
            {\Large \textbf{Ejercicio: Entrenamiento de U-Net}}
        \end{center}
        \begin{figure}
            \centering
            \includegraphics[width=0.6\textwidth]{unet-model}
        \end{figure}
    \end{frame}
    
    % ----------- Anuncio -----------------------
    \begin{frame}{¡Anuncio!}{Visión computacional profunda}
        \begin{center}
            {\Large \textbf{Próxima sesión: Modelado profundo de secuencias (con Mtro. Paco)}}
        \end{center}
    \end{frame}
	
\end{document}

%%% Local Variables:
%%% mode: lualatex
%%% TeX-master: Rodolfo Ferro
%%% End:
